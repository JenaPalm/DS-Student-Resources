```c-lms
activity-type: quiz
activity-name: DS107L8.7 Data Pipeline Query Redshift Quiz
max-attempts: 3
shuffle-questions: false
points-per-question: 0
due-at: 100%
close-at: end-of-module
```

__________________________ is a web service that helps you reliably process and move data between different AWS compute and storage services, as well as on-premises data sources, at specified intervals. 
1. **AWS Data Pipeline**
2. AWS Data Lake
3. AWS Data Lake Analytics
4. AWS Data Lake Storage

With ____________________, you can regularly access your data where itâ€™s stored, transform and process it at scale, and efficiently transfer the results to AWS services such as Amazon S3, Amazon RDS, Amazon DynamoDB, and Amazon EMR.
1. AWS Data Lake 
2. **WS Data Pipeline**
3. AWS Data Lake Analytics
4. AWS Data Lake Storage

True or False? AWS Data Pipeline is a web service that you can use to automate the movement and transformation of data.
1. **True**
2. False

What is Task Runner?
1. A program that is installed and runs automatically on resources created by your pipeline definitions.
1. A program that can be installed anywhere, on any compatible hardware or operating system, provided that it can communicate with the AWS Data Pipeline web service.
3. A program that polls for tasks then performs them.
4. A program that can copy files from Amazon S3 and launches Amazon EMR clusters.
5. **All the above**

True or False? AWS Data Pipeline is a web service that helps you reliably process and move data between different AWS compute and storage services, as well as on-premises data sources, at specified intervals.

For accessing AWS Data Pipeline, __________________ provides low-level APIs that you call using HTTPS requests.
1. AWS Management Console
2. AWS SDKs
3. AWS Command Line Interface (AWS CLI)
4. **Query API**

___________________ provides language-specific APIs and takes care of many of the connection details, such as calculating signatures, handling request retries, and error handling.
1. AWS Management Console
2. **AWS SDKs**
3. AWS Command Line Interface (AWS CLI)
4. Query API

____________________ provides commands for a broad set of AWS services, including AWS Data Pipeline, and is supported on Windows, macOS, and Linux.
1. AWS Management Console
2. AWS SDKs
3. **AWS Command Line Interface (AWS CLI)**
4. Query API

_____________________ provides a web interface that you can use to access AWS Data Pipeline.
1. **AWS Management Console**
2. AWS SDKs
3. AWS Command Line Interface (AWS CLI)
4. Query API

To work with data in your Amazon Redshift cluster, you need ____________________ for connectivity from your client computer or instance.
1. AWS Data Pipeline
2. **Amazon Redshift JDBC, ODBC, or Python drivers**
3. AWS Data Pipeline SDK
4. AWS Data Pipeline Query API

To connect to your Amazon Redshift cluster with your SQL client tool, you need the cluster connection string. You can find the cluster connection string in the
1. AWS Data Pipeline
2. Amazon Redshift JDBC, ODBC, or Python drivers
3. **Amazon Redshift console, on a cluster's details page.**
4. AWS Data Pipeline Query API

To connect to your Amazon Redshift cluster with your SQL client tool, you need the cluster connection string. You can find the cluster connection string in the Amazon Redshift console, on a cluster's details page. The cluster connection string is in the following format:
1. jdbc:redshift://<clustername>.<region>.redshift.amazonaws.com:5439/dev
2. conn = redshift_connector.connect(host='cluster.abc.us-west-1.redshift.amazonaws.com',database='dev',user='awsuser',password='my_password')
3. Driver={Amazon Redshift (x64)}; Server=cluster.abc.us-west-2.redshift.amazonaws.com; Database=dev; UID=adminuser; PWD=my_password; Port=5439
4. **all the above**

To query databases hosted by your Amazon Redshift cluster you can use the following tools:
1. AWS EMR
2. **Connect to your cluster and run queries on the AWS Management Console with the query editor or connect to your cluster through a SQL client tool, such as SQL Workbench**
3. AWS S3
4. AWS QuickSight



