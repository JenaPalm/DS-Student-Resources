```c-lms
activity-type: exam
activity-name: DS107L10.1 Big Data Analytics Final Exam
max-attempts: 3
shuffle-questions: false
points-per-question: 1
due-at: 100%
close-at: end-of-module
```

In Data Analytics Lab 2, what is the sum total of this SQL command on the taxi data? 
```SQL
SELECT sum (total), paytype FROM yellow WHERE paytype = '1' GROUP BY paytype;
```
- 4532000056
- **1351232654**
- 3245000056
- 1251232655

In Data Analytics Lab 2, what is the sum total of this SQL command on the taxi data? 
```SQL
SELECT sum (total), paytype FROM creditcard WHERE paytype = '1' GROUP BY paytype;
```
- 4532000056
- 3245000056
- 1251232655
- **1351232654**

In Data Analytics Lab 2, what does this command do? 
```SQL 
CREATE TABLE taxidata.creditcard
WITH (
  format = 'PARQUET'
  )AS
  SELECT * from "yellow"
  WHERE paytype = '1';
  ``` 
- **It creates a table called creditcard in the taxidata database.**
  - It partitions the data of all credit card transactions into a table called creditcard in the taxidata database.
- It creates a table called creditcard in the yellow database.
- It creates a table called yellow in the taxidata database.
- It creates a table called yellow in the yellow database.

Data Analytics Lab 2 Challenge question one: _Write a query that identifies the most common pickup location in January 2017._
- SELECT sum (total), paytype FROM yellow  WHERE paytype = '1' GROUP BY paytype;
- SELECT count (count) AS "Number of trips" sum (total) AS "Total fares" pickup AS "Trip date" FROM jan GROUP BY pickup;
- **SELECT pulocid, count(*) AS Frequency FROM jan GROUP BY pulocid ORDER BY Count(*) DESC Limit 1;**
- SELECT sum (total), paytype FROM creditcard WHERE paytype = '1' GROUP BY paytype;

Data Analytics Lab 2 Challenge question two: _Write a query to compare the average distance for trips that were paid with credit cards and the average distance for trips that were paid with cash in January 2017._
- SELECT * FROM "taxidata"."yellow" limit 10;
- **SELECT AVG (distance), paytype FROM jan GROUP BY paytype;**
- SELECT sum (total), paytype FROM creditcard WHERE paytype = '1' GROUP BY paytype;
- SELECT payment_type, AVG(trip_distance) FROM nyc_taxi_data WHERE pickup_datetime BETWEEN '2017-01-01' AND '2017-01-31' GROUP BY payment_type ORDER BY AVG(trip_distance) DESC LIMIT 1;

Data Analytics Lab 2 Challenge question: what is highest average distance for trips that were paid with credit cards in January 2017?
- 2.14
- 2.23
- 2.36
- **2.47**

Data Analytics Lab 2 Challenge question: what is highest average distance for trips that were paid with cash in January 2017?
- **2.03**
- 2.14
- 2.36
- 2.47


Data Analytics Lab 3 Challenge question: What is the query you would create to answer the challenge question? Write a query in Athena to count the number of stations that are not in the US or Canada. The first two characters of the station ID field indicate the country where the station is located. The country codes for the United States is US and the country code for Canada is CA.

- **SELECT count (col0) FROM "stations"."stations" WHERE col0 NOT LIKE 'CA%' AND col0 NOT LIKE 'US%';**
- SELECT count (col0) FROM "stations"."stations" WHERE col0 LIKE 'CA%' AND col0 LIKE 'US%';
- SELECT count (col0) FROM "stations"."stations" WHERE col0 IN 'CA%' AND col0 IN 'US%';
- SELECT count (col0) FROM "stations"."stations" WHERE col0 NOT LIKE 'CA%' OR col0 NOT LIKE 'US%';


Data Analytics Lab 4 Challenge one: Write a query to find events in the highest 99.9 percentile for all-time gross sales. Hint: The structured query language (SQL) ntile function will return a dataset into a group of buckets as specified by the function's argument. For example, ntile(1000) orders will return the highest 99.9 percentile for a dataset of orders.

- SELECT buyerid, ntile(1000) OVER (ORDER By pricepaid DESC) AS Percentage FROM sales;
- **SELECT salesid, ntile(1000) OVER (ORDER By pricepaid DESC) AS Percentage FROM sales;**
- SELECT eventid, ntile(1000) OVER (ORDER By pricepaid DESC) AS Percentage FROM sales;
- SELECT qtysold, ntile(1000) OVER (ORDER By pricepaid DESC) AS Percentage FROM sales;


Data Analytics Lab 4 Challenge two: Write a query to list the event IDs and the total sales for each event in descending order.

- SELECT buyerid, SUM (qtysold) AS total FROM sales GROUP BY eventid ORDER BY total DESC;
- **SELECT eventid, SUM (qtysold) AS total FROM sales GROUP BY eventid ORDER BY total DESC;**
- SELECT eventid, SUM (qtysold) AS total FROM sales GROUP BY eventid ORDER BY total DESC;
- SELECT qtysold, SUM (qtysold) AS total FROM sales GROUP BY eventid ORDER BY total DESC;

In the results from Data Analytics Lab 4 Challenge two, which eventid had the largest value and what was that value?

- 7895, 100
- 6845, 98
- **1602, 122**
- 2079, 106

Data Analytics Lab 5: What is the the underlying opensource project that Amazon SageMaker uses to run notebooks?

- **Jupyter**
- Apache
- Spark
- Hadoop

What would be the command to copy a the flightdata.csv to complete the challenge question? remember in the lab for the taxi data from an S3 bucket to another S3 bucket or local terminal location? aws s3 cp s3://aws-tc-largeobjects/CUR-TF-200-ACBDFO-1/Lab5/yellow_tripdata_2017-01.csv  yellow_tripdata_2017-01.csv.

- aws s3 cp s3://aws-tc-largeobjects/CUR-TF-200-ACBDFO-1/Lab5/flightdata.csv
- aws s3 cp ec2://aws-tc-largeobjects/CUR-TF-200-ACBDFO-1/Lab5/flightdata.csv
- **aws s3 cp s3://aws-tc-largeobjects/CUR-TF-200-ACBDFO-1/Lab5/flightdata.csv flight_data.csv**
- aws s3 cp eb2://aws-tc-largeobjects/CUR-TF-200-ACBDFO-1/Lab5/flightdata.csv

Data Analytics Lab 5 Challenge: AnyCompany Airlines has collected sample data for flight departures. They asked you to analyze the data to determine if there is an association between departure times and flight delays. You can access [the sample data from Amazon S3](https://aws-tc-largeobjects.s3-us-west-2.amazonaws.com/CUR-TF-200-ACBDFO-1/Lab5/flightdata.csv). Develop a visualization that will describe this association. In this notebook how would you connect to the data to form the visualization? 

- **df = pd.read_csv('/home/ec2-user/flightdata.csv')**
- df = pd.read_excel('/home/ec2-user/flightdata.csv')
- df = pd.read_parquet('/home/ec2-user/flightdata.csv')
- df = pd.read_hive('/home/ec2-user/flightdata.csv')

Data Analytics Lab 6 Challenge: What are the two items you will need to change to load the February data into the the Data Pipeline? 

- **The S3 location for February and the feb table name**
- The EC2 location and the date range
- The RedShift location and the date range
- The Jupyter notebook location and the date range

Data Analytics Lab 6 Challenge: Create a pipeline that will load a second month of data.
Determine the most common pickup locations for each of the two months. The February data is in the following Amazon S3 location: s3://aws-tc-largeobjects/CUR-TF-200-ACBDFO-1/Lab6/February . Select and accurate SQL query to find the top pickup locations for February 2017.

- **SELECT COUNT (vendorid)as total, pulocationid from public."feb" GROUP BY pulocationid ORDER BY total DESC;**
- SELECT pulocid, count(*) AS Frequency FROM feb GROUP BY pulocid ORDER BY Count(*) ASC Limit 1;
- SELECT pulocid, count(*) AS Frequency FROM feb GROUP BY pulocid ORDER BY Count(*) DESC Limit 2;
- SELECT pulocid, count(*) AS Frequency FROM feb GROUP BY pulocid ORDER BY Count(*) ASC Limit 2;

Data Analytics Lab 6 Challenge: What is the top pick up location for February 2017?
- 132
- 138
- **161**
- 170

Data Analytics Lab 6 Challenge: What is the top pick up location for January 2017?
- 132
- 138
- 161
- **79**

Data Analytics Lab 7 Question: Which application or software would you utilize for searching, viewing, and visualizing data indexed in Elasticsearch and analyzing the data through the creation of bar charts, pie charts, tables, histograms, and maps. A dashboard view combines these visual elements to then be shared via browser to provide real-time analytical views into large data volumes in support of use cases such as: log analytics, application performance monitoring, infrastructure monitoring, and security analytics.
- **Kibana**
- Elasticsearch
- Logstash
- Beats

Data Analytics Lab 8 Question: As a MacOS or Linux user, which command would you use to securely log into your AWS account from the command line?
- **ssh -i labsuser.pem ec2-user@<public-ip>**
- cp -i labsuser.pem ec2-user@<public-ip>
- ftp -i labsuser.pem ec2-user@<public-ip>
- telnet -i labsuser.pem ec2-user@<public-ip>


Data Analytics Lab 8 Question: Which application would you use on Windows to securely log into your AWS account from the command line?
- **PuTTY**
- FTP
- Terminal
- HTTP

Data Analytics Lab 8 Question: How would you add AWS software development kit (SDK) for Python to your session?
- pip install ssh
- pip install aws
- pip install aws-sdk
- **pip install boto3**


Data Analytics Lab 8 Challenge: How would you find the average temperature for a specific location. 

- **SELECT AVG (CAST(temp_max as double)) FROM mydatastore WHERE longitude = '144.9404816' and latitude = '-37.8203537';**
- SELECT AVG (time) FROM weather WHERE location = 'New York';
- SELECT AVG (day) FROM weather WHERE location = 'Maine';
- SELECT AVG (id) FROM weather WHERE location = 'New Hampshire';






